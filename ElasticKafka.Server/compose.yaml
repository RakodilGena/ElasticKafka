volumes:
  kafka-1-data:
  kafka-2-data:
  kafka-3-data:   
  elastic-1-data:
  elastic-2-data:
  elastic-3-data:
    
services:
  
  #Important node: minimum THREE elastic nodes required for successful master-election-quorum
  #if master dies somehow
  elastic-1:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.2 #latest doesn't work
    container_name: elastic-1
    ports:
      - "9201:9200"
    environment:
      - bootstrap.memory_lock=true #prevents swapping memory to disk
      - xpack.security.enabled=false #disabled for dev env

      - node.name=elastic-1
      - cluster.name=elastic-cluster-storage
      
      #other nodes
      - discovery.seed_hosts=elastic-2,elastic-3
      
      #IMPORTANT: remove after cluster is formed
      #- cluster.initial_master_nodes=elastic-1,elastic-2,elastic-3

      #storage initial - max (512mb). inc for prod (eg -Xms2g -Xmx2g for 2 gb)
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m -Dlog4j2.formatMsgNoLookups=true"
    volumes:
      - elastic-1-data:/usr/share/elasticsearch/data
    restart: "on-failure"

  elastic-2:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.2
    container_name: elastic-2
    ports:
      - "9202:9200"
    environment:
      - bootstrap.memory_lock=true #prevents swapping memory to disk
      - xpack.security.enabled=false #disabled for dev env

      - node.name=elastic-2
      - cluster.name=elastic-cluster-storage
      
      #other nodes
      - discovery.seed_hosts=elastic-1,elastic-3
      
      #IMPORTANT: remove after cluster is formed
      #- cluster.initial_master_nodes=elastic-1,elastic-2,elastic-3

      #storage initial - max (512mb). inc for prod (eg -Xms2g -Xmx2g for 2 gb)
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m -Dlog4j2.formatMsgNoLookups=true"
    volumes:
      - elastic-2-data:/usr/share/elasticsearch/data
    restart: "on-failure"
    
  elastic-3:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.2
    container_name: elastic-3
    ports:
      - "9203:9200"
    environment:
      - bootstrap.memory_lock=true #prevents swapping memory to disk
      - xpack.security.enabled=false #disabled for dev env

      - node.name=elastic-3
      - cluster.name=elastic-cluster-storage

      #other nodes
      - discovery.seed_hosts=elastic-1,elastic-2

      #IMPORTANT: remove after cluster is formed
      #- cluster.initial_master_nodes=elastic-1,elastic-2,elastic-3

      #storage initial - max (512mb). inc for prod (eg -Xms2g -Xmx2g for 2 gb)
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m -Dlog4j2.formatMsgNoLookups=true"
    volumes:
      - elastic-3-data:/usr/share/elasticsearch/data
    restart: "on-failure"
    
    
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    restart: always
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      
    

  kafka-1:
    image: confluentinc/cp-kafka:latest
    restart: always
    ports:
      - '9091:9091'
      - '29091:29091'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_BROKER_RACK: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      
      #internal to access from docker cluster, local - to access from elsewhere (from localhost apps too)
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_LISTENERS: LISTENER_INTERNAL://:9091,LISTENER_LOCAL://:29091
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka-1:9091,LISTENER_LOCAL://localhost:29091
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT
        
      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
    volumes:
      - kafka-1-data:/var/lib/kafka1/data
    depends_on:
      - zookeeper

  kafka-2:
    image: confluentinc/cp-kafka:latest
    restart: always
    ports:
      - "9092:9092"
      - '29092:29092'
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_BROKER_RACK: 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_LISTENERS: LISTENER_INTERNAL://:9092,LISTENER_LOCAL://:29092
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka-2:9092,LISTENER_LOCAL://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT

      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
    volumes:
      - kafka-2-data:/var/lib/kafka2/data
    depends_on:
      - zookeeper

  kafka-3:
    image: confluentinc/cp-kafka:latest
    restart: always
    ports:
      - "9093:9093"
      - '29093:29093'
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_BROKER_RACK: 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_INTERNAL
      KAFKA_LISTENERS: LISTENER_INTERNAL://:9093,LISTENER_LOCAL://:29093
      KAFKA_ADVERTISED_LISTENERS: LISTENER_INTERNAL://kafka-3:9093,LISTENER_LOCAL://localhost:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_INTERNAL:PLAINTEXT,LISTENER_LOCAL:PLAINTEXT

      KAFKA_DEFAULT_REPLICATION_FACTOR: 3
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
    volumes:
      - kafka-3-data:/var/lib/kafka3/data
    depends_on:
      - zookeeper
        
        
        
#  automatically creates requested kafka topics
  init-topics:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      echo -e 'Existing topics:'
      kafka-topics --bootstrap-server kafka-1:9091 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka-1:9091 --create --if-not-exists --topic NewMessages --replication-factor 3 --partitions 3
      kafka-topics --bootstrap-server kafka-1:9091 --create --if-not-exists --topic MessageCreatedEvents --replication-factor 3 --partitions 2

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka-1:9091 --list
      "
      
      
  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    restart: always

  
  gateway-service-1:
    image: gatewayservice
    restart: always
    build:
      context: .
      dockerfile: GatewayService/Dockerfile
    ports:
      - "5101:8080"
    environment:
      "MessageServicesUrls:Value": "http://messaging-service-1:8080,http://messaging-service-2:8080,http://messaging-service-3:8080"
      
      "Redis:ConnectionString": "redis:6379"
      
      "Kafka:Consumers:MessageCreatedEvents:Topic": "MessageCreatedEvents"
      "Kafka:Consumers:MessageCreatedEvents:Config:GroupId": "gw_service_message_created_events"
      "Kafka:Consumers:MessageCreatedEvents:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
      "Kafka:Consumers:MessageCreatedEvents:Config:EnableAutoCommit": "false"
      
      "AllowOrigins": "http://localhost"
    depends_on:
      - redis
      - kafka-1
      - kafka-2
      - kafka-3
      
  gateway-service-2:
    image: gatewayservice
    restart: always
    build:
      context: .
      dockerfile: GatewayService/Dockerfile
    ports:
      - "5102:8080"
    environment:
      "MessageServicesUrls:Value": "http://messaging-service-1:8080,http://messaging-service-2:8080,http://messaging-service-3:8080"

      "Redis:ConnectionString": "redis:6379"

      "Kafka:Consumers:MessageCreatedEvents:Topic": "MessageCreatedEvents"
      "Kafka:Consumers:MessageCreatedEvents:Config:GroupId": "gw_service_message_created_events"
      "Kafka:Consumers:MessageCreatedEvents:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
      "Kafka:Consumers:MessageCreatedEvents:Config:EnableAutoCommit": "false"
      
      "AllowOrigins": "http://localhost"
    depends_on:
      - redis
      - kafka-1
      - kafka-2
      - kafka-3
  
  messaging-service-1:
    image: messagingservice
    restart: always
    build:
      context: .
      dockerfile: MessagingService/Dockerfile
    environment:
      "Kafka:Producer:NewMessagesTopic": "NewMessages"
      "Kafka:Producer:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
    depends_on:
      - redis
      - kafka-1
      - kafka-2
      - kafka-3
          
  messaging-service-2:
    image: messagingservice
    restart: always
    build:
      context: .
      dockerfile: MessagingService/Dockerfile
    environment:
      "Kafka:Producer:NewMessagesTopic": "NewMessages"
      "Kafka:Producer:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
    depends_on:
      - redis
      - kafka-1
      - kafka-2
      - kafka-3
        
    
  messaging-service-3:
    image: messagingservice
    restart: always
    build:
      context: .
      dockerfile: MessagingService/Dockerfile
    environment:
      "Kafka:Producer:NewMessagesTopic": "NewMessages"
      "Kafka:Producer:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
    depends_on:
      - redis
      - kafka-1
      - kafka-2
      - kafka-3
  
      
      
  storage-service-1:
    image: storageservice
    restart: always
    build:
      context: .
      dockerfile: StorageService/Dockerfile
    environment:
      "Kafka:Producer:MessageCreatedEventsTopic": "MessageCreatedEvents"
      "Kafka:Producer:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
      "Kafka:Consumers:NewMessages:Topic": "NewMessages"
      "Kafka:Consumers:NewMessages:Config:GroupId": "messaging_service_new_messages"
      "Kafka:Consumers:NewMessages:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
      "Kafka:Consumers:NewMessages:Config:EnableAutoCommit": "false"
    depends_on:
      - redis
      - kafka-1
      - kafka-2
      - kafka-3
      
  storage-service-2:
    image: storageservice
    restart: always
    build:
      context: .
      dockerfile: StorageService/Dockerfile
    environment:
      "Kafka:Producer:MessageCreatedEventsTopic": "MessageCreatedEvents"
      "Kafka:Producer:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
      "Kafka:Consumers:NewMessages:Topic": "NewMessages"
      "Kafka:Consumers:NewMessages:Config:GroupId": "messaging_service_new_messages"
      "Kafka:Consumers:NewMessages:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
      "Kafka:Consumers:NewMessages:Config:EnableAutoCommit": "false"
    depends_on:
      - redis
      - kafka-1
      - kafka-2
      - kafka-3
  
    
  storage-service-3:
    image: storageservice
    restart: always
    build:
      context: .
      dockerfile: StorageService/Dockerfile
    environment:
      "Kafka:Producer:MessageCreatedEventsTopic": "MessageCreatedEvents"
      "Kafka:Producer:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
      "Kafka:Consumers:NewMessages:Topic": "NewMessages"
      "Kafka:Consumers:NewMessages:Config:GroupId": "messaging_service_new_messages"
      "Kafka:Consumers:NewMessages:Config:BootstrapServers": "kafka-1:9091,kafka-2:9092,kafka-3:9093"
      "Kafka:Consumers:NewMessages:Config:EnableAutoCommit": "false"
    depends_on:
      - redis
      - kafka-1
      - kafka-2
      - kafka-3